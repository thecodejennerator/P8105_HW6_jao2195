---
title: "Homework Assignment 6 <br> (P8105_HW6_jao2195)"
author: "Jennifer Osei <br>"
date: '`r format(Sys.time(), "%A %B %d, %Y")`'
output: github_document
---
################################################################################
### Problem 0 ##################################################################
################################################################################
Problem 0
This “problem” focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files. 

To that end: <br> 
-Create a public GitHub repo + local R Project; we suggest naming this repo / directory p8105_hw6_YOURUNI (e.g. p8105_hw6_ajg2202 for Jeff), but that’s not required <br> 

-Create a single .Rmd file named p8105_hw6_YOURUNI.Rmd that renders to github_document
create a subdirectory to store the local data files used in the assignment, and use relative paths to access these data files submit a link to your repo via Courseworks <br> 

Your solutions to Problems 1 and 2 should be implemented in your .Rmd file, and your git commit history should reflect the process you used to solve these Problems. <br> 

For this Problem, we will assess adherence to the instructions above regarding repo structure, git commit history, and whether we are able to knit your .Rmd to ensure that your work is reproducible. Adherence to appropriate styling and clarity of code will be assessed in Problems 1+ using the style rubric. <br> 

This homework includes figures; the readability of your embedded plots (e.g. font sizes, axis labels, titles) will be assessed in Problems 1+.

```{r, message=FALSE}
#Needed libaries

# install.packages("tidyverse")
# install.packages("modelr")
# install.packages("boot")

library(tidyverse)
library(modelr)
library(boot)
library(dplyr)
```

################################################################################
### Problem 1 ##################################################################
################################################################################

Background: The Washington Post has gathered data on homicides in 50 large U.S. cities and made the data available through a GitHub repository here. You can read their accompanying article here.

**Problem 1A** <br> 
**1aQ**
Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. For this problem, limit your analysis those for whom victim_race is white or black. Be sure that victim_age is numeric.

**1aC**
```{r message=FALSE, q1_data_cleaning}
homicide_df =
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |>
    dplyr::mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) |>
  dplyr::filter(victim_race %in% c("White", "Black")) |>
  dplyr::filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) |>
  dplyr::select(city_state, resolution, victim_age, victim_sex, victim_race)
```

**1aA**
In the data cleaning code below we create a `city_state` variable, change `victim_age` to numeric, modifiy victim_race to have categories white and non-white, with white as the reference category, and create a `resolution` variable indicating whether the homicide is solved. Lastly, we filtered out the following cities: Tulsa, AL; Dallas, TX; Phoenix, AZ; and Kansas City, MO; and we retained only the variables `city_state`, `resolution`, `victim_age`, `victim_sex`, and `victim_race`.


**Problem 1B**  <br> 
**1bQ** 
For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

**1bA.** 
Next we fit a logistic regression model using only data from Baltimore, MD. We model `resolved` as the outcome and `victim_age`, `victim_sex`, and `victim_race` as predictors. We save the output as `baltimore_glm` so that we can apply `broom::tidy` to this object and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims.

**1bC**
```{r}
baltimore_glm =
  dplyr::filter(homicide_df, city_state == "Baltimore, MD") |>
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |>
  broom::tidy() |>
  mutate(
    OR = exp(estimate),
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |>
  filter(term == "victim_sexMale") |>
  dplyr::select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

**Problem 1C** <br> 
**1cQ** 
Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

**1cA** 
Below, by incorporating `nest()`, `map()`, and `unnest()` into the preceding Baltimore-specific code, we fit a model for each of the cities, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. We show the first 5 rows of the resulting dataframe of model results.

**1cC**
```{r}
model_results =
  homicide_df %>%
  nest(data = -city_state) %>%
  dplyr::mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race,
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) %>%
  dplyr::select(-models, -data) %>%
  unnest(cols = tidy_models) %>%
  dplyr::mutate(
    OR = exp(estimate),
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") |>
  dplyr::select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |>
  knitr::kable(digits = 3)
```

**Problem 1D** <br>
**1dQ** <br>
Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

**1dA**
Below we generate a plot of the estimated ORs and CIs for each city, ordered by magnitude of the OR from smallest to largest. From this plot we see that most cities have odds ratios that are smaller than 1, suggesting that crimes with male victims have smaller odds of resolution compared to crimes with female victims after adjusting for victim age and race. This disparity is strongest in New yrok. In roughly half of these cities, confidence intervals are narrow and do not contain 1, suggesting a significant difference in resolution rates by sex after adjustment for victim age and race. 

**1dC**
```{r}

Model_Results = model_results |>
  mutate(city_state = fct_reorder(city_state, OR)) |>
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#Added ggsave to organize files and store problem output plots in a folder.
ggsave("plots/Problem_1_Model_Results.png",
        plot = Model_Results, device = "png", width = 10, height = 6, dpi = 300)

Model_Results
```

################################################################################
### Problem 2 ##################################################################
################################################################################

**Problem 2** <br>

**Problem 2a** <br> 
For this problem, we’ll use the Central Park weather data similar to data we’ve seen elsewhere. The code chunk below (adapted from the course website) will download these data.

```{r message=FALSE}
#2a.Downloading data needed for Problem 2: Central Park Weather Data.
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  dplyr::select(name, id, everything())
```

**Problem 2b** <br> 
The bootstrap is helpful when you’d like to perform inference for a parameter / value / summary that doesn’t have an easy-to-write-down distribution in the usual repeated sampling framework. We’ll focus on a simple linear regression with tmax as the response with tmin and prcp as the predictors, and are interested in the distribution of two quantities estimated from these data:

**Quantity 1: r^2**  <- Interested in producing r^2 distribution. <br>
**Quantity 2: log(β̂1xβ̂2)**   <- Interested in producing log(β̂1xβ̂2) distribution as well. 

1) Use 5000 bootstrap samples and for each bootstrap sample. <br> 
2) Produce estimates of these two quantities (R-Squared and Log(B1B2). <br> 
3) Plot the distribution of your estimates, and describe these in words. <br> 
4) Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂^2 and log(β̂1xβ̂2). <br>

**Note:** broom::glance() is helpful for extracting r̂^2 from a fitted regression, and
broom::tidy() (with some additional wrangling) should help in computing log(β̂ 1xβ̂ 2)

```{r warning=FALSE}
## Problem 2b: Bootstrapping

# NOTES: TA in Discussion Board Stated that there was a TYPO in Problem 2. Should be b1b2 NOT b0b1. ~ Canvas 11/21/2023 ###

# weather_df (Dataset)
# tmax (Outcome/Response (Y)) 
# tmin & prcp (Predictor/Explanatory (X))

### Bootstrap Method ######
################################################################################
### Part 1 - R Squared #########################################################
################################################################################
# Creating Boostrapped R Squared
r_squared = weather_df %>%                                                        # Piping Weather Dataset.
                 modelr::bootstrap(n = 5000) %>%                                  # Bootstrapping 5000 iterations for R Squared Sample (#1 Complete)
                 mutate(models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x) ), # linear model with tmax regressed with tmin + prcp.
                        results = map(models, broom::glance)) %>%                 # Using broom::glance for R^2.
                 dplyr::select(-models,-strap) %>%                                # Dropping columns.
                 unnest(results)                                                  # Unnesting Results/Estimates; Final Bootstrapped R-Squared Data.
                                                                                  # (#2 Complete)
# Creating R-Squared Plot
r_squared_plot =  r_squared %>%                                                   # Taking Final Bootstrapped R-Squared Data; Creating Density Plot.
                  ggplot(aes(x = r.squared)) + geom_density()                     # Final Bootstrapped R-Squared Density Plot. 
                     

# Displaying Bootstrapped R-Squared Plot in Knitted Document. (#3 Complete)
r_squared_plot
```
#### Desciption of R-Squared in Words (#3 Complete)

The distribution of the R-Squared Bootstrapped Plot above looks generally mildly left skewed <br> 
in its distribution with a mean (average) value of R-squared of approximately 0.92. 

```{r}
# Calculating 95% Confidence Interval (CI) (2.5% and 97.5% quantiles) for Bootstrapped R^2.
ci_r_squared <- r_squared %>%
                summarize (
                ci_lower = quantile(r.squared, 0.025),
                ci_upper = quantile(r.squared, 0.975))

# Print the confidence interval (CI) for r_squared in neat, organized kable table (#4 Complete)
knitr::kable(ci_r_squared, digits=3)

```

```{r warning=FALSE}
################################################################################
### Part 2 - Log(b1b2) #########################################################
################################################################################

# Creating Boostrapped Log(b1b2) 
log_b1b2 = weather_df %>%                                                         # Piping Weather Dataset.
                modelr::bootstrap(n = 5000) %>%                                   # Bootstrapping 5000 iterations for Log(b1b2) Sample (#1 Complete)
                mutate(models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),   # linear model with tmax regressed with tmin + prcp.
                results = map(models, broom::tidy)) %>%                           # Using broom::tidy for Log(b1b2).
                dplyr::select(-strap, -models) %>%                                # Dropping columns.
                unnest(results) %>%                                               # Unnesting Results/Estimates; Final Bootstrapped Log(b1b2) Data.
                                                                                  # (#2 Complete)     
  
                dplyr::select(id = `.id`, term, estimate) %>%                     # Selecting desired columns from the Bootstrapped Log(b1b2) Data.
                pivot_wider(names_from = term, values_from = estimate) %>%        # Pivot wides to change data form/structure.
                rename(beta1 = tmin, beta2 = prcp) %>%                            # Rename for ease of understanding. 
                mutate(log_b1b2 = log(beta1 * beta2))                             # Adding additional column with desired Log(Beta1 * Beta2).
                                                                                                                                                  
                                
# Creating Log(b1b2) Plot.
log_b1b2_plot = log_b1b2%>% 
                ggplot(aes(x = log_b1b2)) + geom_density()

# Displaying Bootstrapped Log(b1b2) Plot in Knitted Document. (#3 Complete)
log_b1b2_plot

```

#### Desciption of Log(b1b2) in Words (#3 Complete)

The distribution of the Log(b1b2) Bootstrapped Plot above looks generally very left skewed <br> 
in its distribution. This plot looks even more left skewed than the previous R-Squared plot above. 
The Log(b1b2) has a with a mean (average) value of Log(b1b2) of approximately -0.5.25. 


```{r}
# Calculating 95% Confidence Interval (CI) (2.5% and 97.5% quantiles)for Bootstrapped log(b1b2) 
ci_log_b1b2 <- log_b1b2 %>% 
                dplyr::filter(!is.na(log_b1b2)) %>% 
                summarize(
                ci_lower = quantile(log_b1b2, 0.025),
                ci_upper = quantile(log_b1b2, 0.975))

# Print the confidence interval (CI) for log(b1*b2) in neat, organized kable table. (#4 Complete)
knitr::kable(ci_log_b1b2, digits=3)

########################
### END OF PROBLEM 2####
########################
```




################################################################################
### Problem 3 ##################################################################
################################################################################
In this problem, you will analyze data gathered to understand the effects of several variables on a child’s birthweight. This dataset, available here, consists of roughly 4000 children and includes the following variables:

`babysex`: baby’s sex (male = 1, female = 2) <br>
`bhead`: baby’s head circumference at birth (centimeters) <br>
`blength`: baby’s length at birth (centimeteres) <br>
`bwt`: baby’s birth weight (grams) <br>
`delwt`: mother’s weight at delivery (pounds) <br>
`fincome`: family monthly income (in hundreds, rounded) <br>
`frace`: father’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other, 9 = Unknown) <br>
`gaweeks`: gestational age in weeks <br>
`malform`: presence of malformations that could affect weight (0 = absent, 1 = present) <br>
`menarche`: mother’s age at menarche (years) <br>
`mheigth`: mother’s height (inches) <br>
`momage`: mother’s age at delivery (years) <br>
`mrace`: mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other) <br>
`parity`: number of live births prior to this pregnancy <br>
`pnumlbw`: previous number of low birth weight babies <br>
`pnumgsa`: number of prior small for gestational age babies <br>
`ppbmi`: mother’s pre-pregnancy BMI <br>
`ppwt`: mother’s pre-pregnancy weight (pounds) <br>
`smoken`: average number of cigarettes smoked per day during pregnancy <br>
`wtgain`: mother’s weight gain during pregnancy (pounds) <br>

**3** 
**3A** 
Load and clean the data for regression analysis <br> 
(i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r message=FALSE}
#Loading in Dataset, Birthweight 
birthweight <-read_csv("data/birthweight.csv")

birthweight <- birthweight |> #Overwritting dataset
        janitor::clean_names()
      
change_to_factor <- c("babysex", "frace", "malform", "mrace")

#Change to Factor 
birthweight_cleaned <- birthweight |>
                      mutate(across(all_of(change_to_factor), as.factor))

class(birthweight_cleaned$babysex)

# Checking the Factors Factored Appropriately 
# levels(birthweight_cleaned$babysex)
# levels(birthweight_cleaned$frace)
# levels(birthweight_cleaned$mrace)
# levels(birthweight_cleaned$malform)

#Checking Missing Data 

any_NA <- any(is.na(birthweight_cleaned))

if (any_NA) {
  print("There is missing data in the dataset.")
} else {
  print("There is no missing data in the dataset.")
}

#The birthweight_cleaned dataset is now ready for regression analysis. 
```
**3B** 
**Model 1:** Propose a regression model for birthweight. 

This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. 
(I chose to build model based on a hypothesized structure for the factors that underly birthweight in Model 1, below.)

Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.

```{r}
#My Proposed Birthweight Model: 
my_proposed_bw_model1 = lm(bwt ~ mrace + parity + gaweeks + smoken + momage, data = birthweight_cleaned)

#Plot of Model of Residuals against fitted 

#Old school way of looking at model
summary(my_proposed_bw_model1)
summary(my_proposed_bw_model1)$coef
coef(my_proposed_bw_model1)
fitted.values(my_proposed_bw_model1)

#New School way of looking at model
my_proposed_bw_model1 |> 
  broom::glance() 

my_proposed_bw_model1 |> 
  broom::tidy() 
 
#Making simplified table of estimates and coefficients. 
my_proposed_bw_model1 |> 
  broom::tidy() |> 
  dplyr::select(term, estimate, p.value) |> 
  knitr::kable(digits = 3)


modelr::add_residuals(birthweight_cleaned, my_proposed_bw_model1)
modelr::add_predictions(birthweight_cleaned, my_proposed_bw_model1)
  
  
  birthweight_cleaned |> 
  modelr::add_residuals(my_proposed_bw_model1) |> 
  ggplot(aes(x = parity, y = resid)) + geom_violin()
  
  birthweight_cleaned |> 
  modelr::add_residuals(my_proposed_bw_model1) |> 
  ggplot(aes(x = mrace, y = resid)) + geom_violin()
    
    
  birthweight_cleaned |> 
  modelr::add_residuals(my_proposed_bw_model1) |> 
  ggplot(aes(x = parity, y = resid)) + geom_violin()
      
      
  birthweight_cleaned |> 
  modelr::add_residuals(my_proposed_bw_model1) |> 
  ggplot(aes(x = parity, y = resid)) + geom_violin()

# Assuming 'your_model' is your linear regression model
# Assuming 'your_data' is your dataset used to fit the model

library(ggplot2)
library(broom)

# # Generate predictions and residuals
# predictions <- predict(your_model, newdata = your_data)
# residuals <- residuals(your_model)
# 
# # Combine predictions and residuals in a data frame
# plot_data <- data.frame(.fitted = predictions, .resid = resids)
# 
# # Create the plot
# final_plot = ggplot(plot_data, aes(x = .fitted, y = .resid)) +
#   geom_point() +
#   geom_smooth(se = FALSE, method = "loess", color = "red") +
#   labs(title = "Residuals vs. Fitted Values",
#        x = "Fitted Values",
#        y = "Residuals")
# 
# final_plot

```

**### Description of Modeling Process**
### Step 1) For my modeling process, I considered potential covariates that may most likely play a 
#significant role in the birthweight of the child. From my own understanding of biology and som research, the covariates that I fould to most likely effect a childs bithweight was the following: `mrace` , `parity`, `gaweeks`, `smoken`, `momage`. The other covariates my place a role, but these were slected as highly likely to impact birthwaeigh, our outcome of interest. 

Compare your model (Model 1) to two others (Model 2 and Model 3 below) :
**Model 2:** One using length at birth and gestational age as predictors (main effects only).

```{r}
comparison_model_2= lm( bwt ~ blength + gaweeks, data = birthweight_cleaned)
```


**Model 3:** One using head circumference, length, sex, and all interactions (including the three-way interaction) between these.
```{r}
comparision_model_3= lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex +blength*babysex + bhead*blength*babysex, data =  birthweight_cleaned)
```

Make this comparison in terms of the cross-validated prediction error; use `crossv_mc` and functions in purrr as appropriate.
Note that although we expect your model to be reasonable, model building itself is not a main idea of the course and we don’t necessarily expect your model to be “optimal”.

```{r}
# purrr::crossv_mc ()


```


################################################################################
############# END OF HOMEWORK 6  ###############################################
################################################################################

